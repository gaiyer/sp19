# Lecture 5: Performance & ISA #

## Review: ISA ##
* ISA is a contract
* aspects:
  * two types: fixed-length, variable-length
* data lives in:
	* the PC (program counter) is a special register
	* registers are fast bc they're in the CPU
	* memory is outside the CPU and slow
	* could be in the instruction itself (I-type)

# RISC vs CISC #
* Intel x86: CISC but with micro-operations made of RISC
	* allows you to enjoy benefits of both CISC and RISC (like a mix of both)

# Designing a high-performance ISA #
1. Make the common case fast
	* aligned access
	* how big is: struct foo { char c; int i; } [avoid unaligned access!]
 	* pick good load/store architecture
	* Deciding memory / address size
		* "64-bit" means each program can address 2^64 bytes
2. Make the fast case common
	* fill this in ??

# Pipelining #
* sequential instruction execution: next instruction starts before previous finishes
* laundry example: 30min wash, 60min dry, 15min fold
	* 1 load: 30 + 60 + 15 = 105 mins  
	* 2 loads: 30 + 60 + 15 + (60-15) + 15 = 165 mins
		* the second wash can happen during the first dry; the second dry can happen during the first fold, and then there are 45 more minutes of drying + 15 more minutes of folding
		* therefore, the only extra time is the 60
	* 100 loads: 105 + (60)x99 = 6045 mins

## latency vs throughput ##
* single instruction latency: every instruction takes exactly one clock cycle
	* CPI and IPC both = 1
	* TODO double check: we need to make smaller programs, not faster instructions (improving latency, not throughput)
* pipeline: split each instruction into stages (e.g. fetch, dec, and exec)
	* can execute different stages at the same time
	* instruction throughput improved, but not latency
	* each instruction takes the same number of stages, but instructions enter and leave at a faster rate

## inter-instruction parallelism ##
* pipelining: cut datapath into N stages (e.g. 5)
	* special registers added in between each stage (called pipeline stage registers) to store while waiting
	* one instruction in each stage in each cycle
	* set the cycle time = longest stage time
	* base CPI = 1 in theory but pipeline must often stall
	* individual insn latency increases (pipeline overhead = bc cycle time is longer than what it would've been in single-cycle)

## 5-stage pipelined datapath ##
* F(etch), D(ecode), X(ecute), M(memory = read/write), W(riteback)
* nothing special about 5, just common
* latches = pipeline registers = named after the stage they feed into (PC, D, X, M, W)
